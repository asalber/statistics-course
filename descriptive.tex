% Author: Alfredo SÃ¡nchez Alberca (asalber@gmail.com)
\section{Frequency distributions: Tabulation and charts}

\mode<presentation>{
%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Frequency distribution: Tabulation and charts}
\tableofcontents[sectionstyle=show/hide,hideothersubsections]
\end{frame}
}


%---------------------------------------------------------------------slide----
\begin{frame} 
\frametitle{Descriptive Statistics}
Descriptive Statistics is the part of Statistics in charge of representing, analysing and summarizing the information
contained in the sample.

After the sampling process, is the next step in every statistical study and usually consists of:
\begin{enumerate}
\item Classify, group and sort the data of the sample.
\item Tabulate and plot data according to their frequencies.
\item Calculate numerical measures that summarize the information contained in the sample (\emph{sample statistics}).
\end{enumerate} 

It has no inferential power $\Rightarrow$ \alert{\emph{Do not generalize to the population!}} 
\end{frame}


\subsection{Frequency distribution}
%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Sample classification}
The study of a statistical variable starts measuring the variable in the individuals of the sample and classifying the
values.

There are two ways of classifying data:
\begin{description}
\item[Non-grouping] Sort values from lowest to highest value (if there is an order).
Used with qualitative variables and discrete variables with few distinct values.
\item[Grouping] Group values in intervals (classes) and sort them from lowest to highest intervals. 
Used with continuous variables and discrete variables with many distinct values. 
\end{description}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Sample classification}
$X=$Height
\begin{center}
\scalebox{0.6}{\input{img/descriptive/sample_classification}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Frequency count}
$X=$Height
\begin{center}
\scalebox{0.6}{\input{img/descriptive/frequency_count}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Sample frequencies}
\begin{definition}[Sample frequencies]
Given a sample of $n$ values of a variable $X$, for every value $x_i$ of the variable
is defined 
\begin{itemize}
\item \structure{Absolute frequency $n_i$}: Is the number of times that value $x_i$ appears in the sample.
\item \structure{Relative frequency $f_i$}: Is the proportion of times that value $x_i$ appears in the sample.
\[
f_i = \frac{n_i}{n}
\]
\item \structure{Cumulative absolute frequency $N_i$}: Is the number of values in the sample less than or equal to
$x_i$.
\[
N_i = n_1 + \cdots + n_i
\]
\item \structure{Cumulative relative frequency $F_i$}: Is the proportion of values in the sample less than or equal to
$x_i$.
\[
F_i = \frac{N_i}{n}
\]
\end{itemize}
\end{definition}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Frequency table}
The set of values of a variable with their respective frequencies is called \structure{\textbf{frequency distribution}}
of the variable in the sample, and it is usually represented as a \structure{\textbf{frequency table}}.
\begin{center}
\begin{tabular}{|>{\centering}p{1.8cm}|>{\centering}p{1.8cm}|>{\centering}p{1.8cm}|>{\centering}p{1.8cm}|p{1.8cm}<{\centering}|}
\hline
\structure{$X$ values} & \structure{Absolute frequency} & \structure{Relative frequency} & \structure{Cumulative
absolute frequency} & \structure{Cumulative relative frequency} \\
\hline
$x_1$ & $n_1$ & $f_1$ & $N_1$ & $F_1$\\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$\\
$x_i$ & $n_i$ & $f_i$ & $N_i$ & $F_i$\\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$\\
$x_k$ & $n_k$ & $f_k$ & $N_k$ & $F_k$\\
\hline
\end{tabular}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Frequency table}
\framesubtitle{Example of quantitative variable and non-grouped data}
The number of children in 25 families are:
\begin{center}
1, 2, 4, 2, 2, 2, 3, 2, 1, 1, 0, 2, 2, \\
 0, 2, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2
\end{center}
The frequency table for the number of children in this sample is 
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rrrrr}
\hline
x_i & n_i & f_i & N_i & F_i\\
\hline
0 & 2 & 0.08 & 2 & 0.08\\
1 & 6 & 0.24 & 8 & 0.32\\
2 & 14 & 0.56 & 22 & 0.88\\
3 & 2  & 0.08 & 24 & 0.96\\
4 & 1 & 0.04 & 25 & 1 \\
\hline
\sum & 25 & 1 \\
\hline
\end{array}
\]
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Frequency table}
\framesubtitle{Example of quantitative variable and grouped data}
The heights (in cm) of 30 students are:
\begin{center}
179, 173, 181, 170, 158, 174, 172, 166, 194, 185,\\
162, 187, 198, 177, 178, 165, 154, 188, 166, 171,\\
175, 182, 167, 169, 172, 186, 172, 176, 168, 187.
\end{center}
The frequency table for the height in this sample is
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rrrrr}
\hline
\multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{f_i} & \multicolumn{1}{c}{N_i} & \multicolumn{1}{c}{F_i}\\
\hline
(150,160] & 2 & 0.07 & 2 & 0.07\\
(160,170] & 8 & 0.27 & 10 & 0.34\\
(170,180] & 11 & 0.36 & 21 & 0.70\\
(180,190] & 7  & 0.23 & 28 & 0.93\\
(190,200] & 2 & 0.07 & 30 & 1 \\
\hline
\sum & 30 & 1 \\
\hline
\end{array}
\]
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Classes construction}
Intervals are known as \structure{\textbf{classes}} and the center of intervals as \structure{\textbf{class mark}}.

When grouping data into intervals, the following rules must be taken into account: 
\begin{itemize}
\item The number of intervals should not be too big nor too small. 
A usual rule of thumb is to take a number of intervals approximately $\sqrt{n}$ or $\log_2(n)$.
\item The intervals must not overlap and must cover the entire range of values.
It doesn't matter if intervals are left-open and right-closed or vice versa. 
\item The minimum value must fall in the first interval and the maximum value in the last.
\end{itemize}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Frequency table}
\framesubtitle{Example with qualitative variable}
The blood type of 30 people are:
\begin{center}
A, B, B, A, AB, 0, 0, A, B, B, A, A, A, A, AB,\\
A, A, A, B, 0, B, B, B, A, A, A, 0, A, AB, 0.
\end{center}
The frequency table of the blood type is 
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{crr}
\hline
\multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{f_i} \\
\hline
\mbox{0} & 5 & 0.16 \\
\mbox{A} & 14 & 0.47 \\
\mbox{B} & 8 & 0.27 \\
\mbox{AB} & 3 & 0.10 \\
\hline
\sum & 30 & 1 \\
\hline
\end{array}
\]
\begin{center}
\emph{Why there are not cumulative frequencies?}
\end{center} 
\end{frame}


\subsection{Frequency distribution graphs}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Frequency distribution graphs}
Usually the frequency distribution is also displayed graphically.
 
Depending on the type of variable and if data has been grouped or not, there are different types of charts:
\begin{itemize}
\item Bar chart
\item Histogram
\item Line chart or ogive. 
\item Pie chart
\end{itemize}
\end{frame} 


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Bar chart}
A \structure{bar chart} consists in a set of bars, one for every value or category of the variable, plotted on a
coordinate system.

Usually the values or categories of the variable are represented on the $x$-axis, and the frequencies on the $y$-axis. 
For each value or category of the variable, a bar is draw to the height of its frequency.
The width of the bar is not important but bars should be clearly separated among them. 

Depending on the type of frequency represented in the $y$-axis we get different types of bar charts.
 
Sometimes a polygon, known as \structure{\textbf{frequency polygon}}, is plotted joining the top of every bar.
\end{frame}



%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Absolute frequency bar chart}
\framesubtitle{Non-grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/abs_freq_bar_chart}} 
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Absolute frequency line chart or polygon}
\framesubtitle{Non-grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/abs_freq_bar_chart_polygon}} 
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cumulative absolute frequency bar chart}
\framesubtitle{Non-grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/cum_abs_freq_bar_chart}} 
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cumulative absolute frequency line chart or polygon}
\framesubtitle{Non-grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/cum_abs_freq_bar_chart_polygon}} 
\end{center} 
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Histogram}
A \structure{histogram} is similar to a bar chart but for grouped data.  

Usually the classes or grouping intervals are represented on the $x$-axis, and the frequencies on the $y$-axis. 
For each class, a bar is draw to the height of its frequency.
Contrary to bar charts, the width of bars coincides with the width of classes, and there are no space between two
consecutive bars.

Depending on the type of frequency represented in the $y$-axis we get different types of histograms.
 
Sometimes a polygon, known as \structure{\textbf{frequency polygon}}, is plotted joining the top of every bar.
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Absolute frequency histogram}
\framesubtitle{Grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/abs_freq_histogram}}
\end{center} 
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Absolute frequency histogram}
\framesubtitle{Grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/abs_freq_histogram_polygon}} 
\end{center} 
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cumulative absolute frequency histogram}
\framesubtitle{Grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/cum_abs_freq_histogram}}
\end{center} 
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cumulative absolute frequency line chart or ogive}
\framesubtitle{Grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/cum_abs_freq_histogram_polygon}} 
\end{center} 
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cumulative relative frequency histogram}
\framesubtitle{Grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/cum_rel_freq_histogram}}
\end{center} 
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cumulative relative frequency line chart or ogive}
\framesubtitle{Grouped data}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/cum_rel_freq_histogram_polygon}} 
\end{center} 
\end{frame}
 

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Pie chart}
A \structure{pie chart} consists in a circle divided in slices, one for every value or category of the variable. 
Each slice is called \structure{sector} and its angle or area is proportional to the frequency of the corresponding
value or category. 

Pie charts can represent absolute or relative frequencies, but not cumulative frequencies, and are used with nominal
qualitative variables.
For ordinal qualitative or quantitative variables is better to use bar charts or histograms, cause it's easy to perceive
differences in one dimension (lenght of bars) than in two dimensions (areas of sectors).
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Pie chart}
\framesubtitle{Nominal variables}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/rel_freq_pie_chart}}
\end{center}
\end{frame}


% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Outliers}
One of the main problems in samples are \structure{\textbf{outliers}}, that are values very different from the rest of
values of the sample.
\begin{center}
\includegraphics[scale=0.5]{img/descriptive/outlier.png}
\end{center}

It's important to find out outliers before doing any analysis, cause \alert{\emph{outliers usually distort the
results}}.

They always appears in the ends of the distribution, and can be find out easily with a box and whiskers chart (as 
be showed later).
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Outliers management}
With big samples outliers have less importance and can be left in the sample.

With small samples we have several options:

\begin{itemize}
\item Remove the outlier if it's an error. 
\item Replace the outlier by the lower or higher value in the distribution that is not an outlier if it's not an error
and the outlier doesn't fit the theoretical distribution. 
\item Leave the outlier if it's not an error, and change the theoretical model to fit it to outliers.  
\end{itemize}
\end{frame}
 


\subsection{Sample statistics}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Sample statistics}
The frequency table and charts summarize and give an overview of the distribution of values of the studied variable in
the sample, but it's difficult to describe some aspects of the distribution from it, as for example, which are the most
representative values of the distribution, how is the spread of data, which data could be considered outliers, how is
the symmetry of the distribution. 

To describe those aspects of the sample distribution more specific numerical measures, called
\structure{\textbf{sample statistics}}, are used.

According to the aspect of the distribution that they study, there are different types of statistics:
\begin{description}
\item[Measures of locations:] They measure the values where data are concentrated or that divide the distribution into
equal parts. 
\item[Measures of dispersion:] They measure the spread of data.
\item[Measures of shape:] They measure the symmetry and kurtosis of the distribution.  
\end{description}
\end{frame}


\subsection{Location statistics}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Location statistics}
There are two groups: 

\begin{description}
\item [Central location measures:] They measure the values where data are concentrated, and that usually are in the
centre of the distribution. 
These values are the values that best represents the sample data. 
The most important are:
\begin{itemize}
\item Arithmetic mean
\item Median
\item Mode
\end{itemize}
\item [Non-central location measures:] They divide the sample data into equals parts. 
The most important are:
\begin{itemize}
\item Quartiles.
\item Deciles.
\item Percentiles. 
\end{itemize}
\end{description}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Arithmetic mean}
\begin{definition}[Sample arithmetic mean $\bar{x}$]
The \emph{sample arithmetic mean} of a variable $X$ is the sum of observed values in the sample divided by the sample
size
\[
\bar{x} = \frac{\sum x_i}{n}
\]
\end{definition}
From the frequency table can be calculated with the formula
\[
\bar{x} = \frac{\sum x_in_i}{n} = \sum x_i f_i
\]

In most cases the arithmetic mean is the value that best represent the observed values in the sample. 
\begin{center}
\alert{\emph{Watch out! It can not be calculated with qualitative variables.}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Arithmetic mean calculation}
\framesubtitle{Example with non-grouped data}
Using the data of the sample with the number of children of families, the arithmetic mean is 
\begin{align*}
\bar{x} &= \frac{1+2+4+2+2+2+3+2+1+1+0+2+2}{25}+\\
&+\frac{0+2+2+1+2+2+3+1+2+2+1+2}{25} = \frac{44}{25} = 1.76 \mbox{ hijos}.
\end{align*}
or using the frequency table
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rrrrr}
\hline
\multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{f_i} & \multicolumn{1}{c}{x_in_i} & \multicolumn{1}{c}{x_if_i}\\
\hline
0 & 2 & 0.08 & 0 & 0\\
1 & 6 & 0.24 & 6 & 0.24\\
2 & 14 & 0.56 & 28 & 1.12\\
3 & 2  & 0.08 & 6 & 0.24\\
4 & 1 & 0.04 & 4 & 0.16 \\
\hline
\sum & 25 & 1 & 44 & 1.76 \\
\hline
\end{array}
\]
\[
\bar{x} = \frac{\sum x_in_i}{n} = \frac{44}{25}= 1.76 \qquad \bar{x}=\sum{x_if_i} = 1.76.
\]
That means that the value that best represent the number of children in the families of the sample is $1.76$ children.
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Arithmetic mean calculation}
\framesubtitle{Example with grouped data}
Using the data of the sample of student heights, the arithmetic mean is 
\[
\bar{x} = \frac{179+173+\cdots+187}{30} = 175.07 \mbox{ cm}.
\]
or using the frequency table with the class marks 
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rrrrrr}
\hline
\multicolumn{1}{c}{X} & \multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{f_i} & \multicolumn{1}{c}{x_in_i} & \multicolumn{1}{c}{x_if_i}\\
\hline
(150,160] & 155 & 2 & 0.07 & 310 & 10.33\\
(160,170] & 165 & 8 & 0.27 & 1320 & 44.00\\
(170,180] & 175 & 11 & 0.36 & 1925 & 64.17\\
(180,190] & 185 & 7 & 0.23 & 1295 & 43.17\\
(190,200] & 195 & 2 & 0.07 & 390 & 13 \\
\hline
\sum &  & 30 & 1 & 5240 & 174.67 \\
\hline
\end{array}
\]
\[
\bar{x} = \frac{\sum x_in_i}{n} = \frac{5240}{30}= 174.67 \qquad \bar{x}=\sum{x_if_i} = 174.67.
\]

Observe that when the mean is calculated from the table the result differs a little from the real value, cause the
values used in the calculations are the class marks instead of the actual values.
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Weighted mean}
In some cases the values of the sample have different importance. 
In that case the importance or \emph{weight} of each value of the sample must be taken into account when calculating
the mean. 

\begin{definition}[Sample weighted mean $\bar{x}_p$]
Given a sample of values $x_1,\ldots,x_n$ where every value $x_i$ has a weight $p_i$, the \emph{weighted
mean} of variable $X$ is the sum of the product of each value by its weight, divided by sum of weights
\[
\bar{x}_p = \frac{\sum x_ip_i}{\sum p_i}
\]
\end{definition}

From the frequency table can be calculated with the formula
\[
\bar{x}_p = \frac{\sum x_ip_in_i}{\sum p_i}
\]
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Weighted mean calculation}
Assume that a student wants to calculate a representative measure o its performance in a course. 
The grade and the credits of every subjects are 
\begin{center}
\begin{tabular}{lcc}
\hline
Subject & Credits & Grade\\
\hline
Maths & 6 & 5 \\
Economics & 4 & 3 \\
Chemistry & 8 & 6 \\
\hline
\end{tabular}
\end{center}
The arithmetic mean is 
\[
\bar{x} = \frac{\sum x_i}{n} = \frac{5+3+6}{3}= 4.67 \text{ points},
\]
However, this measure does not represent well the performance of the student, as not all the subjects have the same
importance and require the same effort to pass. 
Subjects with more credits require more work and must have more weight in the calculation of the mean. 

In this case is better to use the weighted mean, using the credits as the
weights of grades, as a representative measure of the student effort
\[
\bar{x}_p = \frac{\sum x_ip_i}{\sum p_i} = \frac{5\cdot 6+3\cdot 4+6\cdot 8}{6+4+8}= \frac{90}{18} = 5 \text{ points}.
\]
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Median}
\begin{definition}[Sample median $Me$]
The \emph{sample median} of a variable $X$ is the value that is in the middle of the ordered sample. 
\end{definition}

The median divides the sample distribution in into two equal parts, that is, there are the same number of values above
and below the median.
It has cumulative frequencies $N_{Me}= n/2$ y  $F_{Me}= 0.5$.

\begin{center}
\alert{\emph{Watch out! It can not be calculated for nominal variables.}}
\end{center}

\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Median calculation}
\framesubtitle{Non-grouped data}
With non-grouped data, there are two possibilities:
\begin{itemize}
\item Odd sample size: The median is the value in the position $\frac{n+1}{2}$.
\item Even sample size: The median is the average of values in positions $\frac{n}{2}$ and $\frac{n}{2}+1$.
\end{itemize}
\begin{center}
\scalebox{0.4}{\input{img/descriptive/median}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Median calculation}
\framesubtitle{Example with non-grouped data}
Using the data of the sample with the number of children of families, the sample size is 25, that is odd, and the median
is the value in the position $\frac{25+1}{2} = 13$ of the sorted sample. 
\[
0,0,1,1,1,1,1,1,2,2,2,2,\fbox{2},2,2,2,2,2,2,2,2,2,3,3,4
\]
and the median is 2 children.

With the frequency table, the median is the lowest value with a cumulative absolute frequency greater than or equal to
$13$, or with a cumulative relative frequency greater than or equal to $0.5$.
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rrrrr}
\hline
x_i & n_i & f_i & N_i & F_i\\
\hline
0 & 2 & 0.08 & 2 & 0.08\\
1 & 6 & 0.24 & 8 & 0.32\\
\rowcolor{coral} \color{color1}2 & 14 & 0.56 & 22 & 0.88\\
3 & 2  & 0.08 & 24 & 0.96\\
4 & 1 & 0.04 & 25 & 1 \\
\hline
\sum & 25 & 1 \\
\hline
\end{array}
\]
\end{frame}

% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{CÃ¡lculo de la mediana con datos agrupados}
% Con datos agrupados la mediana se calcula interpolando en el polÃ­gono de frecuencias absolutas acumuladas para el valor $n/2$.
% \begin{center}
% \scalebox{0.7}{\input{img/descriptive/calculo_mediana_datos_no_agrupados}}
% \end{center}
% \note{Cuando se trabaja con datos agrupados en clases, la mediana se calcula de forma aproximada, interpolando en el
% polÃ­gono de frecuencias acumuladas para el valor $n/2$. 
% 
% La interpolaciÃ³n consiste en proyectar sobre el polÃ­gono la frecuencia $n/2$ y ver a quÃ© altura del eje de abscisas
% corta al polÃ­gono de frecuencias. Dicho valor es la mediana.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{InterpolaciÃ³n en el polÃ­gono de frecuencias absolutas acumuladas}
% \begin{center}
% \scalebox{1}{\input{img/descriptive/interpolacion}}
% \end{center}
% 
% \uncover<3->{
% \[
% Me = l_{i-1}+\frac{n/2 - N_{i-1}}{N_i-N_{i-1}}(l_i-l_{i-1}) = l_{i-1}+\frac{n/2-N_{i-1}}{n_i}a_i
% \]
% }
% 
% \note{La interpolaciÃ³n en realidad consiste en una razÃ³n de semejanza de triÃ¡ngulos. 
% 
% En primer lugar se identifica el intervalo en el que cae la mediana, mirando en la columna de frecuencias acumuladas de
% la tabla de frecuencias, de igual modo a como se hace para datos no agrupados. Una vez identificado el intervalo, se
% toma el segmento del polÃ­gono de frecuencias acumuladas que corresponde a dicho intervalo. Supongamos que dicho
% intervalo tiene lÃ­mite inferior $l_{i-1}$ y lÃ­mite superior $l_i$, y que parte de una frecuencia absoluta acumulada
% $N_{i-1}$ y llega a una frecuencia absoluta acumulada $N_{i}$. Este segmento define un triÃ¡ngulo rectÃ¡ngulo de Ã¡ngulo
% $\alpha$ cuya tangente es el cateto opuesto, que vale $N_i-N_{i-1}$ entre el cateto contiguo, que es precisamente la
% amplitud del intervalo $l_i-l_{i-1}$.
% 
% Por otro lado, si proyectamos la frecuencia corresondiente a la media $n/2$ sobre el polÃ­gono, en el punto de corte
% aparecerÃ­a la mediana, de manera se se tiene otro triÃ¡ngulo rectÃ¡ngulo mÃ¡s pequeÃ±o que es semejante al anterior al
% compartir el mismo Ã¡ngulo $\alpha$. Al igual que antes, la tangente de este Ã¡ngulo serÃ¡ el cateto opuesto, que ahora
% vale $n/2-N_i$ entre el cateto contiguo que ahora vale $Me-l_{i-1}$. 
% 
% Puesto que se trata del mismo Ã¡ngulo, su tangente es la misma y se pueden igual ambas expresiones, dando lugar a una
% ecuaciÃ³n conde la Ãºnica incÃ³gnita es la mediana. Despejandola, se obtiene la fÃ³rmula para calcular la mediana.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{CÃ¡lculo de la mediana}
% \framesubtitle{Ejemplo con datos agrupados}
% En el ejemplo de las estaturas $n/2 =
% 30/2 = 15$. Si miramos en el polÃ­gono de frecuencias acumuladas comprobamos que
% la mediana caerÃ¡ en el intervalo $(170,180]$.
% \begin{center}
% \scalebox{0.7}{\input{img/descriptive/interpolacion_ejemplo_1}}
% \end{center}
% \note{Veamos un ejemplo de interpolaciÃ³n para calcular la mediana de la muestra de estaturas. Mirando en la tabla de
% frecuencias se observa que el primer intervalo con una frecuencia igual o mayor que $n/2=30/2=15$ es el que va de 170
% cm a 180 cm, asÃ­ que se toma el trozo del polÃ­gono de frecuencias absolutas acumuladas corresondiente a este intervalo.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{InterpolaciÃ³n en el polÃ­gono de frecuencias absolutas acumuladas}
% \begin{center}
% \scalebox{1}{\input{img/descriptive/interpolacion_ejemplo_2}}
% \end{center}
% 
% \uncover<3->{
% \[
% Med = 170+\frac{15 - 10}{21-10}(180-170) = 170+\frac{5}{11}10 = 174.54
% \]
% }
% 
% \note{Si nos fijamos en el triÃ¡ngulo grande, la tangente de $\alpha$ vale $21-10$ que es el cateto opuesto, entre
% $180-170$ que es el cateto contiguo, mientras que si nos fijamos en el triÃ¡ngulo pequeÃ±o que aparece al proyectar $15$
% sobre el polÃ­gono, se tiene que la tangente de $\alpha$ vale $15-10$ que es cateto opuesto entre $Me-170$ que es el
% cateto contiguo. Igualando ambas expresiones y despejando la mediana se obtiene $174.54$ cm que es la estatura mediana.
% 
% Una comprobaciÃ³n que conviene hacer siempre es ver que el valor obtenido cae efectivamente dentro del intervalo de
% interpolaciÃ³n.}
% \end{frame}
% 

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Mode}
\begin{definition}[Sample Mode $Mo$]
The \emph{sample mode} of a variable $X$ is the most frequent value in the sample.
\end{definition}

With grouped data the \emph{modal class} is the class with the highest frequency. 

It can be calculated for all types of variables (qualitative and quantitative). 

Some distributions can have more than one mode
\begin{center}
\scalebox{0.4}{\input{img/descriptive/mode}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Mode calculation}
Using the data of the sample with the number of children of families, the value with the highest frequency is $2$, that
is the mode $Mo = 2$ children.
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rr}
\hline
\multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} \\
\hline
0 & 2 \\
1 & 6 \\
\rowcolor{coral}\color{color1} 2 & 14 \\
3 & 2  \\
4 & 1 \\
\hline
\end{array}
\]

Using the data of the sample of student heights, the class with the highest frequency is $(170,180]$ that is the modal
class $Mo=(170,180]$.
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rr}
\hline
\multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} \\
\hline
(150,160] & 2 \\
(160,170] & 8 \\
\rowcolor{coral} \color{color1}(170,180] & 11 \\
(180,190] & 7 \\
(190,200] & 2 \\
\hline
\end{array}
\]
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Which central tendency statistic should I use?}
In general, when all the central tendency statistics can be calculated, is advisable to use them as representative
values in the following order:
\begin{enumerate}
\item Mean. Mean takes more information from the sample than the others, as it takes into account the magnitude
of data.
\item Median. Median takes less information than mean but more than mode, as it takes into account the order
of data.
\item Mode. Mode is the measure that fewer information takes from the sample, as it only takes into account the
absolute frequency of values.
\end{enumerate}

But, \emph{be careful with outliers}, as the mean can be distorted by them.
In that case is better to use the median as the value most representative.

For example, if a sample of number of children of 7 families is
\begin{center}
0, 0, 1, 1, 2, 2, 15

$\bar{x}=3$ children \quad and \quad $Me=1$ children

\emph{Which measure represent better the number of children in the sample?}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Non-central location measures}
The non-central location measures or \emph{quantiles} divide the sample distribution in equal parts.

The most used are:
\begin{description}
\item[Quartiles:] Divide the distribution into 4 equal parts. 
There are 3 quartiles: $C_1$ (25\% acumulated) , $C_2$ (50\% acumulated), $C_3$ (75\% acumulated).
\item[Deciles:] Divide the distribution into 10 equal parts.\\
There are 9 deciles: $D_1$ (10\% acumulated) ,\ldots, $D_9$ (90\% acumulated).
\item[Percentiles:] Divide the distribution into en 100 equal parts.\\
There are 99 percentiles: $P_1$ (1\% acumulated),\ldots, $P_{99}$ (99\% acumulated).
\end{description}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Quantiles}
\begin{center}
\scalebox{0.8}{\input{img/descriptive/quantiles}}
\end{center}
\onslide<4->{
Observe that there is a correspondence between quartiles, deciles and percentiles. 
For example, first quartile coincide with percentile 25, and fourth decile coincides with the percentile 40.}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Quantiles calculation}
Quantiles are calculated in a similar way to the median. 
The only difference lies in the cumulative relative frequency that correspond to every quantile.  
\begin{center}
\scalebox{0.6}{\input{img/descriptive/quantiles_calculation}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Quantile calculation}
\framesubtitle{Example with non-grouped data}
Using the data of the sample with the number of children of families, the cumulative relative frequencies were
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rr}
\hline
\multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{F_i} \\
\hline
0 & 0.08\\
1 & 0.32\\
2 & 0.88\\
3 & 0.96\\
4 & 1\\
\hline
\end{array}
\]

\begin{align*}
F_{C_1}=0.25 &\Rightarrow C_1 = 1 \text{ children},\\
F_{C_2}=0.5 &\Rightarrow C_2 = 2 \text{ children},\\
F_{C_3}=0.75 &\Rightarrow C_3 = 2 \text{ children},\\
F_{D_4}=0.4 &\Rightarrow D_3 = 2 \text{ children},\\
F_{P_{92}}=0.92 &\Rightarrow P_{92} = 3 \text{ children}.\\
\end{align*}
\end{frame}


\subsection{Dispersion statistics}
%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Dispersion statistics}
\emph{Dispersion} or \emph{spread} refers to the variability of data. 
So, dispersion statistics measure how the data values are scattered in general, or with respect to a central location
measure. 

For quantitative variables, the most important are:
\begin{itemize}
\item Range
\item Interquartile range
\item Variance
\item Standard deviation
\item Coefficient of variation
\end{itemize}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Range and interquartile range}
\begin{definition}[Sample range]
The \emph{sample range} of a variable $X$ is the difference between the the maximum and the minimum value in the sample.
\[\text{Range} = \max_{x_i} -\min_{x_i}\]
\end{definition}

The range measure the largest variation among the sample data. 
However, it's very sensitive to outliers, as they appear at the ends of the distribution, and for that reason is
rarely used. 
\begin{center}
\scalebox{0.8}{\input{img/descriptive/range}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Range and interquartile range}
The following measure avoid the problem of outliers and is much more used.

\begin{definition}[Sample interquartile range]
The \emph{sample interquartile range} of a variable $X$ is the difference between the third and the first
sample quartiles.
\[\text{IQR} = Q_3 -Q_1\]
\end{definition}
\begin{center}
\scalebox{0.8}{\input{img/descriptive/interquartile_range}}
\end{center}

The interquartile range measures the spread of the 50\% central data.
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Box plot}
The dispersion of a variable in a sample can be graphically represented with a \structure{\textbf{box plot}}, that
represent five descriptive statistics (minimum, quartiles and maximum) known as the \emph{five-numbers}.
It consist in a box, drawn from the lower to the upper quartile, that represent the interquartile range, and two
segments, known as the lower and the upper \emph{whiskers}.  
Usually the box is split in two with the median. 

This chart is very helpful as it serves to many purposes:  
\begin{itemize}
\item It serves to measure the spread of data as it represent the range and the interquartile range. 
\item It serves to detect outliers, that are the values outside the interval defined by the whiskers.
\item It serves to measure the symmetry of distribution, comparing the length of the boxes and whiskers above and below
the median. 
\end{itemize}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Box plot}
\framesubtitle{Example with newborn weights}
\begin{center}
\scalebox{0.6}{\input{img/descriptive/boxplot}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Box plot construction}
To create a box plot follow the steps below
\begin{enumerate}
\item Calculate the quartiles. 
\item Draw a box from the lower to the upper quartile. 
\item Split the box with the median or second quartile. 
\item For the whiskers calculate first two values called \emph{fences} $f_1$ y $f_2$. The lower fence is the
lower quartile minus one and a half the interquartile range, and the upper fence is the upper quartile plus one and a
half the interquartile range:
\begin{align*}
f_1&=Q_1-1.5\,\text{IQR}\\
f_2&=Q_3+1.5\,\text{IQR}
\end{align*}
The fences define the interval where data are considered normal.
Any value outside that interval is considered an outlier. \\ 
For the lower whisker draw a segment from the lower quartile to the lower value in the sample grater than or
equal to $f_1$, and for the upper whisker draw a segment from the upper quartile to the highest value in the sample lower than
or equal to $f_2$.
\item Finally, if there are some outlier, draw a dot in every outlier. 
\end{enumerate}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Box plot construction}
\framesubtitle{Example of number of children}
\begin{enumerate}
\uncover<2->{\item Calculate the quartiles: $Q_1=1$ children} \uncover<3->{and $Q_2=Q_3=2$ children}
\uncover<4->{\item Draw the box.}
\uncover<5->{\item Calculate the fences $f_1=1-1.5*1=-0.5$ and $f_2=2+1.5*1=3.5$.}
\uncover<6->{\item Draw the whiskers: $w_1=0$ children} \uncover<7->{and $w_2=3$ children.}
\uncover<8->{\item Draw the outliers: 4 children.}
\end{enumerate}
\begin{center}
\scalebox{0.45}{\input{img/descriptive/boxplot_children}}
\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Deviations from the mean}
Another way of measuring spread of data is with respect to a central tendency measure, as for example the mean. 

In that case, it's measured the distance from every value in the sample to the mean, that is called
\structure{\textbf{deviation from the mean.}}

\begin{center}
\scalebox{1}{\input{img/descriptive/deviations}}
\end{center}

If deviations are big, the mean would be less representative as when they are small.
%\begin{center} 
%\emph{Which mean is more representative?}
%\end{center}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Variance and standard deviation}
\begin{definition}[Sample variance $s^2$]
The \emph{sample variance} of a variable $X$ is the average of squared deviations from the mean. 
\[
s^2 = \frac{\sum (x_i-\bar x)^2n_i}{n} = \sum (x_i-\bar x)^2f_i
\]
\end{definition}
It can also be calculated with the formula
\[
s^2 = \frac{\sum x_i^2n_i}{n} -\bar x^2= \sum x_i^2f_i-\bar x^2
\]
The variance has the units of the variable squared, and to ease their interpretation it's common to calculate its square
root.

\begin{definition}[Sample standard deviation $s$]
The \emph{sample standard deviation} of a variable $X$ is the square root of the variance.
\[
s = +\sqrt{s^2}
\]
\end{definition}
\end{frame}


% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{InterpretaciÃ³n de la varianza y la desviaciÃ³n tÃ­pica}
% Tanto la varianza como la desviaciÃ³n tÃ­pica sirven para cuantificar la dispersiÃ³n de los datos en torno a la media. 
% %Si la dispersiÃ³n es grande la media serÃ¡ menos representativa de la muestra que si la dispersiÃ³n es pequeÃ±a.
% \begin{center}
% \includegraphics[scale=0.4]{img/descriptive/interpretacion_varianza}
% 
% %\emph{Â¿En quÃ© caso es mÃ¡s representativa la media?}
% \end{center}
% 
% \note{Tanto la varianza como la desviaciÃ³n tÃ­pica sirven para cuantificar la dispersiÃ³n de los datos en torno a la media. Si la dispersion
% con respecto a la media es pequeÃ±a, los individuos se parecerÃ¡n bastante a la media y esta serÃ¡ mÃ¡s representativa que cuando los
% individuos no se parezcana ella y la dispersiÃ³n con respecto a la media sea mayor.}
% \end{frame}
% 
% 
%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Variance and standard deviation calculation}
\framesubtitle{Example with non-grouped data}
Using the data of the sample with the number of children of families, and adding a new column to the frequency table
with the squared values, 
\[
\setlength\arraycolsep{3mm}
\setlength\arrayrulewidth{0.5pt}
\begin{array}{rrr}
\hline
\multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{x_i^2n_i} \\
\hline
0 & 2 & 0 \\
1 & 6 & 6 \\
2 & 14 & 56\\
3 & 2  & 18\\
4 & 1 & 16 \\
\hline
\sum & 25 & 96 \\
\hline
\end{array}
\]
\[
s^2 = \frac{\sum x_i^2n_i}{n}-\bar x^2 = \frac{96}{25}-1.76^2= 0.7424 \mbox{ children}^2.
\]
and the standard deviation is $s=\sqrt{0.7424} = 0.8616$ children.

Compared to the range, that is 4 children, the standard deviation is not very large, so we can conclude
that the dispersion of the distribution is small and consequently the mean, $\bar x=1.76$ children, represents quite
well the number of children of families of the sample. 
\end{frame}


% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{CÃ¡lculo de la varianza y la desviaciÃ³n tÃ­pica}
% \framesubtitle{Ejemplo con datos agrupados}
% En el ejemplo de las estaturas, al ser datos agrupados, el cÃ¡lculo se realiza igual que antes pero tomando como valores de la variable las
% marcas de clase. 
% \begin{center}
% \setlength\arraycolsep{3mm}
% \setlength\arrayrulewidth{0.5pt}
% \begin{array}{rrrr}
% \hline
% \multicolumn{1}{c}{X} & \multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{x_i^2n_i} \\
% \hline
% (150,160] & 155 & 2 & 48050\\
% (160,170] & 165 & 8 & 217800\\
% (170,180] & 175 & 11 & 336875\\
% (180,190] & 185 & 7 & 239575\\
% (190,200] & 195 & 2 & 76050\\ 
% \hline 
% \sum &  & 30 & 918350 \\
% \hline
% \end{array}
% \end{center}
% \[
% s^2 = \frac{\sum x_i^2n_i}{n}-\bar x^2 = \frac{918350}{30}-174.67^2= 102.06 \mbox{ cm}^2.
% \]
% Y la desviaciÃ³n tÃ­pica es $s=\sqrt{102.06} = 10.1$ cm.
% 
% Este valor es bastante pequeÃ±o, comparado con el recorrido de la variable, que va de 150 a 200 cm, por lo que la variable tiene poca
% dispersiÃ³n y en consecuencia su media es muy representativa.
% 
% \note{En el ejemplo de las estaturas, como se habÃ­an agrupado los datos, como valores se tomarÃ¡n las
% marcas de clases, es decir, 155 elevado al cuadrado y por su frecuencia absoluta que es 2, lo que nos da 48050, y asÃ­ sucesivamente. DespuÃ©s
% hay que sumar los valores de esta columna y dividirlos por el tamaÃ±o de la muestra que era 30. Finalmente al cociente se le resta el valor
% de la media que era $174.67$ elevada al cuadrado, lo que nos da 102.06 cm al cuadrado.
% 
% Si sacamos la raÃ­z cuadrada se obtiene una desviaciÃ³n tÃ­pica de 10.1 cm, que es un valor pequeÃ±o comparado con el recorrido de la variable
% que va de 150 a 200 cm, por lo que se puede concluir que la muestra tiene poca dispersiÃ³n y por tanto la media representa muy bien al resto
% de individuos de la muestra.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de variaciÃ³n}
% Tanto la varianza como la desviaciÃ³n tÃ­pica tienen unidades y eso dificulta a veces su interpretaciÃ³n y su comparaciÃ³n.
% 
% Afortunadamente es fÃ¡cil definir a partir de ellas una medida de dispersiÃ³n adimensional que es mÃ¡s fÃ¡cil de interpretar.
% \begin{definition}[Coeficiente de variaciÃ³n muestral $cv$]
% El \emph{coeficiente de variaciÃ³n muestral} de una variable $X$ se define como el cociente entre su desviaciÃ³n tÃ­pica muestral y el valor absoluto de su media muestral.
% \[
% cv = \frac{s}{|\bar x|}
% \]
% \end{definition}
% El coeficiente de variaciÃ³n muestral mide la dispersiÃ³n relativa de los valores de la muestra en torno a la media muestral.
%  
% Como no tiene unidades, es muy sencillo de interpretar: Cuanto mayor sea, mayor serÃ¡ la dispersiÃ³n y menos
% representativa serÃ¡ la media.
% 
% TambiÃ©n se utiliza para comparar la dispersiÃ³n entre muestras distintas incluso si las variables tienen unidades diferentes.
% \begin{center}
% \alert{\emph{Â¡Ojo! No tiene sentido cuando la media muestral vale 0 o valores prÃ³ximos.}}
% \end{center}
% 
% \note{Tanto la varianza como la desviaciÃ³n tÃ­pica tienen unidades lo que dificulta a veces su interpretaciÃ³n.
% 
% Afortunadamente es fÃ¡cil definir a partir de ellas una medida de dispersiÃ³n adimensional que es mÃ¡s fÃ¡cil de interpretar.
% 
% El coeficiente de variaciÃ³n muestral, que se representa mediante cv, se defiene como el cociente entre la desviaciÃ³n tÃ­pica y el valor
% absoluto de la media.
% 
% Como tanto la desviaciÃ³n tÃ­pica como la media tienen las unidades de la variable, al hacer su cociente las unidades desaparecen y se obtiene
% una medida adimensional que resulta mÃ¡s sencilla de interpretar. 
% 
% Al estar dividido por el valor absoluto de la media, el coeficiente de variaciÃ³n mide la dispersiÃ³n relativa de los valores de la muestra
% en torno a la media muestral, y como en el numerador estÃ¡ la desviaciÃ³n tÃ­pica, cuanto mayor sea esta, mayor serÃ¡ el coeficiente de
% variaciÃ³n y por tanto mayor serÃ¡ la dispersiÃ³n relativa de la variable en torno a la media.
% 
% Una de las principales utilidades del coeficiente de variaciÃ³n es que, precisamente por no tener unidades, permite la comparaciÃ³n de la
% dispersiÃ³n de muestras distintas, incluso si son de variables con distintas unidades. 
% 
% El Ãºnico problema de este estadÃ­stico es que no vale cuando la media muestral vale 0 o prÃ³xima a 0, ya que al estar en el denominador,
% obtendrÃ­amos valores muy grandes.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de variaciÃ³n}
% \framesubtitle{Ejemplo}
% En el caso del nÃºmero de hijos, como $\bar x=1.76$ hijos y $s=0.8616$ hijos, se tiene que el coefiente de variaciÃ³n vale
% \[
% cv = \frac{s}{|\bar x|} = \frac{0.8616}{|1.76|} = 0.49.
% \]
% En el caso de las estaturas, como $\bar x=174.67$ cm y $s=10.1$ cm, se tiene que el coeficiente de variaciÃ³n vale 
% \[
% cv = \frac{s}{|\bar x|} = \frac{10.1}{|174.67|} = 0.06.
% \]
% Como se puede observar la dispersiÃ³n relativa en la muestra de estaturas es mucho menor que en la del nÃºmero de hijos, por lo que la media
% de las estaturas serÃ¡ mÃ¡s representativa que la media del nÃºmero de hijos. 
% \end{frame}
% 
% 
% \subsection{EstadÃ­sticos de forma}
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{EstadÃ­sticos de forma}
% Son medidas que tratan de caracterizar aspectos de la forma de la distribuciÃ³n de una muestra.
% 
% Los aspectos mÃ¡s relevantes son:
% \begin{description}
% \item[SimetrÃ­a:] Miden la simetrÃ­a de la distribuciÃ³n de frecuencias en torno a la media.\\
% El estadÃ­stico mÃ¡s utilizado es el \emph{Coeficiente de AsimetrÃ­a de Fisher}.
% \item[Apuntamiento:] Miden el apuntamiento de la distribuciÃ³n de frecuencias.\\
% El estadÃ­stico mÃ¡s utilizado es el \emph{Coeficiente de Apuntamiento o Curtosis}.
% \end{description}
% \note{Los estadÃ­sticos de forma se encargan de describir, como su propio nombre indica, la forma que tiene la distribuciÃ³n de valores en la
% muestra, en particular se estudian dos aspectos que son la asÃ­metrÃ­a y el apuntamiento.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de asimetrÃ­a}
% \begin{definition}[Coeficiente de asimetrÃ­a muestral $g_1$]
% El \emph{coeficiente de asimetrÃ­a muestral} de una variable $X$ se define como el promedio de las desviaciones de los
% valores de la muestra respecto de la media muestral, elevadas al cubo, dividido por la desviaciÃ³n tÃ­pica al cubo. \[g_1
% = \frac{\sum (x_i-\bar x)^3 n_i/n}{s^3} = \frac{\sum (x_i-\bar x)^3 f_i}{s^3}\]
% \end{definition}
% El coeficiente de asimetrÃ­a muestral mide el grado de simetrÃ­a de los valores de la muestra con respecto a la media muestral, de manera que:
% \begin{itemize}
% \item $g_1=0$ indica que hay el mismo nÃºmero de valores a la derecha y a la izquierda de la media (simÃ©trica).
% \item $g_1<0$ indica que la mayorÃ­a de los valores son mayores que la media (asimÃ©trica a la izquierda).
% \item $g_1>0$ indica que la mayorÃ­a de los valores son menores que la media (asimÃ©trica a la derecha).
% \end{itemize}
% 
% \note{La simetrÃ­a con respecto a la media tiene que ver con la ubicaciÃ³n de los valores a un lado y otro de la media, cuÃ¡ntos valores hay
% por encima y cuÃ¡ntos por debajo, y cÃ³mo estÃ¡n de alejados.
% 
% El coeficiente de asimetrÃ­a muestral, que se representa $g_1$ se define, como la suma del producto de las desviaciones de los valores de la
% muestra a la media muestral elevadas al cubo por su frecuencia absoluta, dividida por el tamaÃ±o de la muestra, y a su vez todo dividido
% por la desviaciÃ³n tÃ­pica al cubo.
% 
% Como las desviaciones elevadas al cubo tienen las unidades de la variable al cubo y la desviaciÃ³n tÃ­pica elevada al cubo tambiÃ©n tiene las
% unidades de la variable al cubo, al realizar el cociente las unidades se cancelan y por tanto el coeficiente de asimetrÃ­a es una medida
% adimensional que mide el grado de asimetrÃ­a de los valores de la muestra con respecto a la media, de manera que:
% \begin{itemize}
% \item $g_1=0$ indica que hay el mismo nÃºmero de valores a la derecha y a la izquierda de la media y por tanto la distribuciÃ³n es simÃ©trica.
% \item $g_1<0$ indica que la mayorÃ­a de los valores son mayores que la media y entonces se dice que la distribuciÃ³n es asimÃ©trica hacia la
% izquierda.
% \item $g_1>0$ indica que la mayorÃ­a de los valores son menores que la media y entonces se dice que la distribuciÃ³n es asimÃ©trica hacia la
% derecha.
% \end{itemize}
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de asimetrÃ­a}
% \framesubtitle{Ejemplo de distribuciÃ³n simÃ©trica}
% \begin{center}
% \scalebox{0.8}{\input{img/descriptive/distribucion_simetrica}}
% \end{center}
% \note{AquÃ­ tenemos el histograma de una distribuciÃ³n simÃ©trica. Como puede observarse, la media queda justo en el centro de la
% distribuciÃ³n, coincidiendo con la mediana y existe el mismo nÃºmero de barras y con la misma frecuencia a un lado y a otro de la media.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de asimetrÃ­a}
% \framesubtitle{Ejemplo de distribuciÃ³n asimÃ©trica hacia la izquierda}
% \begin{center}
% \scalebox{0.8}{\input{img/descriptive/distribucion_asimetrica_izquierda}}
% \end{center}
% \note{En este otro caso tenemos una distribuciÃ³n asimÃ©trica hacia la izquierda, donde la media queda por debajo de la mediana y las barras
% son mÃ¡s altas a la derecha de la media, lo que indica que hay mÃ¡s valores por encima de la media. Por debajo de la media habrÃ­a menos
% valores, barras mÃ¡s bajas, pero mÃ¡s alejados.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de asimetrÃ­a}
% \framesubtitle{Ejemplo de distribuciÃ³n asimÃ©trica hacia la derecha}
% \begin{center}
% \scalebox{0.8}{\input{img/descriptive/distribucion_asimetrica_derecha}}
% \end{center}
% \note{Y en este otro caso tenemos una distribuciÃ³n asimÃ©trica hacia la derecha, donde la media queda por encima de la mediana y las barras
% son mÃ¡s altas a la izquierda de la media, lo que indica que hay mÃ¡s valores por debajo de la media. Por encima de la media habrÃ­a menos
% valores, barras mÃ¡s bajas, pero mÃ¡s alejados.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{CÃ¡lculo del coeficiente de asimetrÃ­a}
% \framesubtitle{Ejemplo con datos agrupados}
% Siguiendo con el ejemplo de las estaturas, podemos calcular el coeficiente de asimetrÃ­a a partir de la tabla de frecuencias aÃ±adiendo una
% nueva columna con los cubos de las desviaciones a la media $\bar x = 174.67$ cm:
% \begin{center}
% \setlength\arraycolsep{3mm}
% \setlength\arrayrulewidth{0.5pt}
% \begin{array}{rrrrr}
% \hline
% \multicolumn{1}{c}{X} & \multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{x_i-\bar x} & \multicolumn{1}{c}{(x_i-\bar x)^3 n_i} \\
% \hline
% (150,160] & 155 & 2 & -19.67 & -15221.00\\
% (160,170] & 165 & 8 & -9.67 & -7233.85\\
% (170,180] & 175 & 11 & 0.33 & 0.40\\
% (180,190] & 185 & 7 & 10.33 & 7716.12\\
% (190,200] & 195 & 2 & 20.33 & 16805.14\\ 
% \hline  
% \sum &  & 30 & & 2066.81 \\
% \hline
% \end{array}
% \end{center}
% \[
% g_1 = \frac{\sum (x_i-\bar x)^3n_i/n}{s^3} = \frac{2066.81/30}{10.1^3} = 0.07.
% \]
% Al estar tan prÃ³ximo a 0, este valor indica que la distribuciÃ³n es prÃ¡cticamente simÃ©trica con respecto a la media. 
% 
% \note{Para calcular el coeficiente de asimetrÃ­a en el ejemplo de las estaturas se puede aÃ±adir una nueva columna a la
% tabla de frecuencias con las desviaciones de los valores a la media que recordemos valÃ­a $174.67$ cm. Como habÃ­amos agrupado los datos en
% clases, para calcular las desviaciones a la media se toma la marca de cada clase. AsÃ­, la primera desviaciÃ³n es 155 menos la media 174.67 lo
% que nos da $-19.67$ cm, la segunda es 165 menos $174.67$ cm y asÃ­ sucesivamente. ObsÃ©rvese que las desviaciones de los valores menos que la
% media serÃ¡n negativas y que las de los valores mayores serÃ¡n positivas. A continuaciÃ³n se aÃ±ade otra columna a la tabla con el producto de
% las desviaciones elevadas al cubo por su frecuencia absoluta, es decir, $-19.67$ al cubo por su frecuencia absoluta que es 2, lo que nos da
% $-15221$, $-9.67$ elevado al cubo y por su frecuencia absoluta que es 8, lo que nos da $-7233.85$, y asÃ­ sucesivamente. Al final se suman
% los valores de esta columna y se dividen por el tamaÃ±o de la muestra que era 30. Por Ãºltimo el resultado de este cociente se vuelve a dividir por la desviaciÃ³n tÃ­pica
% que era $10.1$ cm elevada al cubo, y se obtiene $0.07$.
% 
% Como este valor estÃ¡ muy prÃ³ximo a 0, se puede concluir que la distribuciÃ³n de las estaturas es prÃ¡cticamente simÃ©trica.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de apuntamiento o curtosis}
% \begin{definition}[Coeficiente de apuntamiento muestral $g_2$]
% El \emph{coeficiente de apuntamiento muestral} de una variable $X$ se define como el promedio de las desviaciones de
% los valores de la muestra respecto de la media muestral, elevadas a la cuarta, dividido por la desviaciÃ³n tÃ­pica a la
% cuarta y al resultado se le resta 3. \[g_2 = \frac{\sum (x_i-\bar x)^4 n_i/n}{s^4}-3 = \frac{\sum (x_i-\bar x)^4 f_i}{s^4}-3\]
% \end{definition}
% El coeficiente de apuntamiento muestral mide el grado de apuntamiento de los valores de la muestra con respecto a una distribuciÃ³n normal de referencia, de manera que:
% \begin{itemize}
% \item $g_2=0$ indica que la distribuciÃ³n tienen un apuntamiento normal (\emph{mesocÃºrtica}).
% \item $g_2<0$ indica que la distribuciÃ³n tiene menos apuntamiento de lo normal (\emph{platicÃºrtica}).
% \item $g_2>0$ indica que la distribuciÃ³n tiene mÃ¡s apuntamiento de lo normal (\emph{leptocÃºrtica}).
% \end{itemize}
% 
% \note{El apuntamiento de una distribuciÃ³n muestral tiene que ver con la pendiente su polÃ­gono de frecuencias.
% 
% El coeficiente de apuntamiento o kurtosis muestral, que se representa $g_2$ se define, como la suma del producto de las desviaciones de los
% valores de la muestra a la media muestral elevadas a la cuarta por su frecuencia absoluta, dividida por el tamaÃ±o de la muestra, y a su vez
% todo dividido por la desviaciÃ³n tÃ­pica a la cuarta, y al final se resta 3 al cociente. Como puede verse, la fÃ³rmula es muy parecida a la del
% coeficiente de asimetrÃ­a, pero tomando las potencias cuartas en lugar de las potencias al cubo, y restando 3 al cociente. 
% 
% Al igual que para el coeficiente de asimetrÃ­a, como las desviaciones elevadas a la cuarta tienen las unidades de la variable a la cuarta y
% la desviaciÃ³n tÃ­pica elevada al cubo tambiÃ©n tiene las unidades de la variable a la cuarta, al realizar el cociente las unidades se cancelan
% y por tanto el coeficiente de apuntamiento es una medida adimensional que mide el grado de apuntamiento de la distribuciÃ³n muestral.
% 
% El apuntamiento suele medirse en comparaciÃ³n con un apuntamiento de referencia que es el de una distribuciÃ³n normal. La distribuciÃ³n normal
% se verÃ¡ maÅ adelante en el curso, pero baste decir que es la distribuciÃ³n mÃ¡s comÃºn que se presenta en la naturaleza, y por lo tanto, estÃ¡
% justificado tomarla como referencia y comparar el apuntamiento de cualquier otra distribuciÃ³n con el de la distribuciÃ³n normal que siempre
% vale 0. Por tanto cuando
% \begin{itemize}
% \item $g_2=0$ indica que la distribuciÃ³n tienen un apuntamiento normal (\emph{mesocÃºrtica}).
% \item $g_2<0$ indica que la distribuciÃ³n tiene menos apuntamiento de lo normal (\emph{platicÃºrtica}).
% \item $g_2>0$ indica que la distribuciÃ³n tiene mÃ¡s apuntamiento de lo normal (\emph{leptocÃºrtica}
% \end{itemize}
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de apuntamiento o curtosis}
% \framesubtitle{Ejemplo de distribuciÃ³n mesocÃºrtica}
% \begin{center}
% \scalebox{0.8}{\input{img/descriptive/distribucion_mesocurtica}}
% \end{center}
% \note{AquÃ­ un histograma con coeficente de apuntamiento 0 y sobre Ã©l una distribuciÃ³n normal, representada por esta curva conocida
% como campana de Gauss. ObsÃ©rvese cÃ³mo la altura de las barras coinciden con la campaÃ±a de Gauss y se ajustan perfectamente a la
% distribuciÃ³n normal, lo que indica que la distribuciÃ³n es mesocÃºrtica.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de apuntamiento o curtosis}
% \framesubtitle{Ejemplo de distribuciÃ³n platicÃºrtica}
% \begin{center}
% \scalebox{0.8}{\input{img/descriptive/distribucion_platicurtica}}
% \end{center}
% \note{Ahora tenemos un histograma con un coeficiente de apuntamiento menor que 0. Como se puede apreciar, en este caso la altura de las
% barras centrales estÃ¡n por debajo de la campa de Gauss y la distribuciÃ³n tiene menos apuntamiento de lo normal, por lo que se dice que es
% platicÃºrtica.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Coeficiente de apuntamiento o curtosis}
% \framesubtitle{Ejemplo de distribuciÃ³n leptocÃºrtica}
% \begin{center}
% \scalebox{0.8}{\input{img/descriptive/distribucion_leptocurtica}}
% \end{center}
% \note{En este otro caso tenemos un histograma con un coeficiente de apuntamiento mayor que 0. Ahora la altura
% de las barras centrales estÃ¡n por encima de la campa de Gauss y la distribuciÃ³n tiene mÃ¡s apuntamiento de lo normal, por lo que se dice
% que es leptocÃºrtica.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{CÃ¡lculo del coeficiente de apuntamiento}
% \framesubtitle{Ejemplo con datos agrupados}
% De nuevo para el ejemplo de las estaturas podemos calcular el coeficiente de asimetrÃ­a a partir de la tabla de frecuencias aÃ±adiendo una
% nueva columna con las desviaciones a la media $\bar x = 174.67$ cm elevadas a la cuarta: 
% \begin{center}
% \setlength\arraycolsep{3mm}
% \setlength\arrayrulewidth{0.5pt}
% \begin{array}{rrrrr}
% \hline
% \multicolumn{1}{c}{X} & \multicolumn{1}{c}{x_i} & \multicolumn{1}{c}{n_i} & \multicolumn{1}{c}{x_i-\bar x} & \multicolumn{1}{c}{(x_i-\bar x)^4 n_i} \\
% \hline
% (150,160] & 155 & 2 & -19.67 & 299396.99\\
% (160,170] & 165 & 8 & -9.67 & 69951.31\\
% (170,180] & 175 & 11 & 0.33 & 0.13\\
% (180,190] & 185 & 7 & 10.33 & 79707.53\\
% (190,200] & 195 & 2 & 20.33 & 341648.49\\ 
% \hline 
% \sum &  & 30 & & 790704.45 \\
% \hline
% \end{array}
% \end{center}
% \[
% g_2 = \frac{\sum (x_i-\bar x)^4n_i/n}{s^4} - 3 = \frac{790704.45/30}{10.1^4}-3 = -0.47.
% \]
% Como se trata de un valor negativo, aunque pequeÃ±o, podemos decir que la distribuciÃ³n es ligeramente platicÃºrtica. 
% 
% \note{El coeficiente de apuntamiento se calcula de manera similar al coeficiente de asimetrÃ­a, calculando primero las desviaciones a la
% meida en una columna de la tabla y luego aÃ±adiendo otra columna con el producto de
% las desviaciones elevadas a la cuarta por su frecuencia absoluta, es decir, $-19.67$ a la cuarta por su frecuencia absoluta que es 2, lo que
% nos da $299396.99$, $-9.67$ elevado a la cuarta y por su frecuencia absoluta que es 8, lo que nos da $69951.31$, y asÃ­ sucesivamente. Al
% final se suman los valores de esta columna y se dividen por el tamaÃ±o de la muestra que era 30. Por Ãºltimo el resultado de este cociente se
% vuelve a dividir por la desviaciÃ³n tÃ­pica que era $10.1$ cm elevada a la cuarta, y al resultado se le resta 3, obteniendo -0.47.
% 
% Como se trata de un valor negativo, aunque prÃ³ximo a cero, se puede concluir que la distribuciÃ³n de las estaturas es ligeramente
% platicÃºrtica. }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{InterpretaciÃ³n de los coeficientes de asimetrÃ­a y apuntamiento}
% Como se verÃ¡ mÃ¡s adelante en la parte de inferencia, muchas de las pruebas estadÃ­sticas solo pueden aplicarse a poblaciones normales.
% 
% Las poblaciones normales se caracterizan por ser simÃ©tricas y mesocÃºrticas, de manera que, tanto el coeficiente de asimetrÃ­a como el de apuntamiento pueden utilizarse para contrastar si los datos de la muestra provienen de una poblaciÃ³n normal.
% 
% En general, se suele rechazar la hipÃ³tesis de normalidad de la poblaciÃ³n cuando $g_1$ o $g_2$ estÃ©n fuera del intervalo $[-2,2]$.
% 
% En tal caso, lo habitual es aplicar alguna transformaciÃ³n a la variable para corregir la anormalidad.
% 
% \note{Como se verÃ¡ mÃ¡s adelante en la parte de inferencia, muchas de las pruebas estadÃ­sticas solo pueden aplicarse a poblaciones normales,
% que se caracterizan por ser simÃ©tricas y mesocÃºrticas, de manera que, tanto el coeficiente de asimetrÃ­a como el de apuntamiento pueden
% utilizarse para comprobar si los datos de la muestra provienen de una poblaciÃ³n normal. 
% 
% En general, se suele rechazar la hipÃ³tesis de normalidad de la poblaciÃ³n cuando $g_1$ o $g_2$ estÃ©n fuera del intervalo $[-2,2]$.
% 
% En tal caso, lo habitual es aplicar alguna transformaciÃ³n a la variable para corregir la anormalidad.
% }
% \end{frame}
% 
% 
% \subsection{Transformaciones de variables}
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Transformaciones de variables}
% En muchas ocasiones se suelen transformar los datos brutos para trabajar con unas unidades mÃ¡s cÃ³modas, o bien para corregir alguna
% anormalidad de la distribuciÃ³n.
% 
% 
% Por ejemplo, si estamos trabajando con estaturas medidas en metros y tenemos los siguientes valores:
% \[ 
% 1.75\mbox{m}, 1.65\mbox{m}, 1.80\mbox{m},
% \]
% podemos evitar los decimales multiplicando por 100, es decir, pasando de metros a centÃ­metros:
% \[ 
% 175\mbox{cm}, 165\mbox{cm}, 180\mbox{cm},
% \]
% Y si queremos reducir la magnitud de los datos podemos restarles a todos el menor de ellos, en este caso, 165cm:
% \[ 
% 10\mbox{cm}, 0\mbox{cm}, 15\mbox{cm},
% \]
% EstÃ¡ claro que este conjunto de datos es mucho mÃ¡s sencillo que el original. En el fondo lo que se ha hecho es aplicar a los datos la
% transformaciÃ³n: \[Y= 100X-165\]
% 
% \note{En muchas ocasiones los datos brutos de la muestra suelen transformarse, a veces simplemente para cambiar a una escala mÃ¡s cÃ³moda y
% otras veces para corregir alguna anormalidad de la distribuciÃ³n.
% 
% Si por ejemplo estamos trabajando con estaturas medidas en metros, con dos decimales como los de este ejemplo, podemos evitar el trabajo
% con decimales multiplicando por 100, es decir, pasando de metros a centÃ­metros. AsÃ­ tenemos que $1.75$ m multiplicado por 100 se transforma
% en 175 cm, $1.65$ m multiplicado por 100 se trasnforma en 165 cm y $1.80$ m se transforma en 180 cm.
% 
% DespuÃ©s, si queremos reducir la magnitud de los datos y pasar de centenas a unidades mÃ¡s pequeÃ±as, podemos restarle a todos los datos el
% mÃ­nimo de los valores que es 165 cm. 175 cm menos 165 cm nos da 10 cm, 165 menos 165 nos da 0 cm y 180 menos 165 nos da 15 cm.
% 
% Con esto los datos pasan a una escala mucho mÃ¡s fÃ¡cil de manejar que la original. En el fondo lo que hemos hecho es aplicar a cada dato la
% transformaciÃ³n lineal $Y=100x-165$.}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Transformaciones lineales}
% Una de las transformaciones mÃ¡s habituales es la \emph{transformaciÃ³n lineal}:
% \[
% Y=a+bX.
% \]
% Se puede comprobar fÃ¡cilmente que la media y la desviaciÃ³n tÃ­pica de la variable resultante cumplen:
% \begin{align*}
% \bar y &= a+ b\bar x,\\
% s_{y} &= |b|s_{x}
% \end{align*}
% AdemÃ¡s, el coeficiente de curtosis no se altera y el de asimetrÃ­a sÃ³lo cambia de signo si $b$ es negativo.
% 
% \note{Una de las transformaciones mÃ¡s habituales que suele realizarse es la \emph{transformaciÃ³n lineal} que sigue la ecuaciÃ³n de una recta
% $Y=a+bX$, donde $a$ es el tÃ©rmino independiente y $b$ la pendiente de la recta.
% 
% Una propiedad que tiene esta transformaciÃ³n y resulta fÃ¡cil de comprobar es que la media de la variable transformada se puede obtener
% aplicando la misma transformaciÃ³n lineal a la media de la variable original, es decir, $\bar y = a+ b\bar x$, y por otro lado, la desviaciÃ³n
% tÃ­pica de la variable transformada se puede obtener multiplicando la desviaciÃ³n tÃ­pica de la variable original por el valor absoluto de la
% pendiente de la trasnformaciÃ³n lineal, es decir,  $s_{y} &= |b|s_{x}$.
% 
% AdemÃ¡s, el coeficiente de curtosis no se altera y el de asimetrÃ­a sÃ³lo cambia de signo si la pendiente es negativa.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{TransformaciÃ³n de tipificaciÃ³n y puntuaciones tÃ­picas}
% Una de las transformaciones lineales mÃ¡s habituales es la \emph{tipificaciÃ³n}:
% \begin{definition}[Variable tipificada]
% La \emph{variable tipificada} de una variable estadÃ­stica $X$ es la variable que resulta de restarle su media y dividir por su desviaciÃ³n tÃ­pica.
% \[
% Z=\frac{X-\bar x}{s_{x}}
% \]
% \end{definition}
% 
% La tipificaciÃ³n es muy Ãºtil para eliminar la dependencia de una variable respecto de las unidades de medida empleadas.
% 
% Los valores tipificados se conocen como \structure{\textbf{puntuaciones tÃ­picas}} y miden el nÃºmero de desviaciones tÃ­picas que dista de la media cada observaciÃ³n, lo cual es Ãºtil para comparar variables con distintas unidades. 
% 
% Otra propiedad de la variable tipificada es que tiene media 0 y desviaciÃ³n tÃ­pica 1:
% \[
% \bar z = 0 \qquad s_{z} = 1
% \]
% 
% \note{Entre las transformaciones lineales hay una de especial importancia, y se conoce como transformaciÃ³n de tipificaciÃ³n. La tipificaciÃ³n
% consiste en dividir las desviaciones de los valores a la media por la desviaciÃ³n tÃ­pica. 
% 
% Como las desviaciones a la media tienen las unidades de la variable y la desviaciÃ³n tÃ­pica tambiÃ©n, al hacer el cociente se cancelan las
% unidades y los valores de la variable tipificada no tienen unidades, por lo que esta transformaciÃ³n es Ãºtil para eliminar la dependencia de
% la variable de las unidades de medida empleadas.
% 
% Los valores tipificados se conocen como \structure{\textbf{puntuaciones tÃ­picas}} y miden el nÃºmero de desviaciones tÃ­picas que dista de la
% media cada observaciÃ³n, lo cual es Ãºtil para comparar variables con distintas unidades.
% 
% Otra propiedad que se deduce de las propiedades de las trasnformaciones lineales vistas antes es que la media de una variable tipificada
% siempre vale 0 y su desviaciÃ³n tÃ­pica 1.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{TransformaciÃ³n de tipificaciÃ³n y puntuaciones tÃ­picas}
% \framesubtitle{Ejemplo}
% Las notas de 5 alumnos en dos asignaturas $X$ e $Y$ son:
% \[
% \begin{array}{rccccccccc}
% \mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\ \cline{1-6}
% X: & 2 & 5 & 4 & \alert{8} & 6 & \qquad & \bar x = 5 & \quad s_x = 2\\
% Y: & 1 & 9 & \alert{8} & 5 & 2 & \qquad & \bar y = 5 & \quad s_y = 3.16\\
% \end{array}
% \]
% \begin{center}
% \emph{Â¿Han tenido el mismo rendimiento los alumnos que han sacado un 8?}
% \end{center}
% PodrÃ­a parecer que ambos alumnos han tenido el mismo rendimiento puesto que tienen la misma nota, pero si queremos ver el rendimiento relativo al resto del grupo, tendrÃ­amos que tener en cuenta la dispersiÃ³n de cada muestra y medir sus puntuaciones tÃ­picas:
% \[
% \begin{array}{cccccc}
% X: & -1.5 & 0 & -0.5 & \alert{1.5} & 0.5 \\
% Y: & -1.26 & 1.26 & \alert{0.95} & 0 & -0.95\\
% \end{array}
% \]
% Es decir, el alumno que tiene un 8 en $X$ estÃ¡ $1.5$ veces la desviaciÃ³n tÃ­pica por encima de la media de su grupo, mientras que el alumno que tiene un 8 en $Y$ sÃ³lo estÃ¡ $0.95$ desviaciones tÃ­picas por encima de su media.
% AsÃ­ pues, el primer alumno tuvo un rendimiento superior al segundo. 
% 
% \note{Para ver la utilidad de la transformaciÃ³n de tipificaciÃ³n, supongamos que tenemos un grupo de 5 alumnos en los que se ha medido la
% nota en dos asignaturas $X$ e $Y$. Si calculamos la media y la desviaciÃ³n tÃ­pica en cada asignatura, se tiene que la nota media en $X$ es
% 5 con una desviaciÃ³n tÃ­pica de $2$ y que la nota media de $Y$ es tambiÃ©n 5 con una desviaciÃ³n tÃ­pica de $3.16$, es decir, hay mÃ¡s dispersiÃ³n
% en las notas de $Y$ que en las de $X$.
% 
% PodrÃ­amos preguntarnos si sacar un 8 en la asignatura $X$ tiene el mismo mÃ©rito que sacar un $8$ en la asignatura $Y$, o dicho de otro modo,
% el alumno que ha sacado un 8 en la asignatura $X$, Â¿ha tenido el mismo rendimiento que el que ha sacado un 8 en la $Y$?
% 
% PodrÃ­a parecer que ambos alumnos han tenido el mismo rendimiento puesto que tienen la misma nota, pero si queremos ver el rendimiento
% relativo al resto del grupo, tendrÃ­amos que tener en cuenta la dispersiÃ³n de cada muestra y medir sus puntuaciones tÃ­picas, que son 
% \[
% \begin{array}{cccccc}
% X: & -1.5 & 0 & -0.5 & \alert{1.5} & 0.5 \\
% Y: & -1.26 & 1.26 & \alert{0.95} & 0 & -0.95\\
% \end{array}
% \]
% Es decir, el alumno que tiene un 8 en $X$ estÃ¡ $1.5$ veces la desviaciÃ³n tÃ­pica por encima de la media de su grupo, mientras que el alumno
% que tiene un 8 en $Y$ sÃ³lo estÃ¡ $0.95$ desviaciones tÃ­picas por encima de su media. AsÃ­ pues, el primer alumno tuvo un rendimiento superior
% al segundo y tiene mÃ¡s mÃ©rito sacar un $8$ en la asignatura $X$ que en la $Y$.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{TransformaciÃ³n de tipificaciÃ³n y puntuaciones tÃ­picas}
% \framesubtitle{Ejemplo}
% Siguiendo con el ejemplo anterior
% \begin{center}
% \emph{Â¿CuÃ¡l es el mejor alumno?}
% \end{center}
% Si simplemente se suman las puntuaciones de cada asignatura se tiene:
% \[
% \begin{array}{rccccc}
% \mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\ \hline
% X: & 2 & 5 & 4 & 8 & 6 \\
% Y: & 1 & 9 & 8 & 5 & 2 \\ \hline
% \sum & 3 & \alert{14} & 12 & 13 & 8 
% \end{array}
% \]
% El mejor alumno serÃ­a el segundo.
% 
% Pero si se considera el rendimiento relativo tomando las puntuaciones tÃ­picas se tiene:
% \[
% \begin{array}{rccccc}
% \mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\ \hline
% X: & -1.5 & 0 & -0.5 & 1.5 & 0.5 \\
% Y: & -1.26 & 1.26 & 0.95 & 0 & -0.95\\ \hline
% \sum & -2.76 & 1.26 & 0.45 & \alert{1.5} & -0.45
% \end{array}
% \]
% Y el mejor alumno serÃ­a el cuarto. 
% 
% \note{Siguiendo con el ejemplo anterior, tambiÃ©n podrÃ­amos habernos preguntado Â¿cuÃ¡l es el mejor alumno?  
% Si simplemente sumamos las puntuaciones de cada asignatura tenemos:
% \[
% \begin{array}{rccccc}
% \mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\ \hline
% X: & 2 & 5 & 4 & 8 & 6 \\
% Y: & 1 & 9 & 8 & 5 & 2 \\ \hline
% \sum & 3 & \alert{14} & 12 & 13 & 8 
% \end{array}
% \]
% El mejor alumno serÃ­a el segundo.
% 
% Pero es mucho mÃ¡s razonable cosiderar el rendimiento relativo tomando las puntuaciones tÃ­picas y entonces se tiene que la suma de las
% puntuaciones tÃ­picas es:
% \[
% \begin{array}{rccccc}
% \mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\ \hline
% X: & -1.5 & 0 & -0.5 & 1.5 & 0.5 \\
% Y: & -1.26 & 1.26 & 0.95 & 0 & -0.95\\ \hline
% \sum & -2.76 & 1.26 & 0.45 & \alert{1.5} & -0.45
% \end{array}
% \]
% Con lo que realmente el mejor alumno es el cuarto. 
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Transformaciones no lineales}
% La transformaciÃ³n $Y=X^2$ comprime la escala para valores pequeÃ±os y la expande para valores altos, de manera que es muy Ãºtil para corregir asimetrÃ­as hacia la izquierda.
% \begin{center}
% \scalebox{1}{
% \begin{pspicture}(0,0)(12,6)
% \rput[l](0,3){\includegraphics[scale=0.4]{img/descriptive/histograma_asimetrico_izquierda.eps}}
% \psline[linewidth=15pt,linecolor=royalblue1,arrowlength=1,arrowinset=0]{->}(5,3)(7,3)
% \rput(6,3){$Y=X^2$}
% \rput[l](7,3){\includegraphics[scale=0.4]{img/descriptive/histograma_simetrico.eps}}
% \end{pspicture}}
% \end{center}
% 
% \note{Otras transformaciones no lineales que son habituales para corregir anormalidades de la muestra son el cuadrado, que comprime la
% escala para valores pequeÃ±os y la expande para valores altos, de manera que es muy Ãºtil para corregir asimetrÃ­as hacia la izquierda, tal y
% como puede apreciarse en estos histogramas.
% }
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Transformaciones no lineales}
% Las transformaciones $Y=\sqrt x$, $Y= \log X$ y $Y=1/X$ comprimen la escala para valores altos y la expanden para valores pequeÃ±os, de manera que son Ãºtiles para corregir asimetrÃ­as hacia la
% derecha.
% \begin{center}
% \scalebox{1}{
% \begin{pspicture}(0,0)(12,6)
% \rput[l](0,3){\reflectbox{\includegraphics[scale=0.4]{img/descriptive/histograma_asimetrico_izquierda.eps}}}
% \psline[linewidth=15pt,linecolor=royalblue1,arrowlength=1,arrowinset=0]{->}(5,3)(7,3)
% \rput(6,3){$Y=\sqrt{X}$}
% \rput[l](7,3){\includegraphics[scale=0.4]{img/descriptive/histograma_simetrico.eps}}
% \end{pspicture}}
% \end{center}
% 
% \note{Mientras que para corregir asimetrÃ­as hacia la derecha se utilizan o bien la raÃ­z cuadrada, la funciÃ³n logarÃ­tmica o la inversa, ya
% que ambas comprimen la escala para valores altos y la expanden para valores pequeÃ±os.}
% \end{frame}
% 
% 


% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Factors}
% Sometimes is interesting to describe the frequency distribution of the main variable for different subsamples
% corresponding to the categories of another variable that is known as \structure{\textbf{classificatory variable}} or
% \structure{\textbf{factor}}.
% 
% \structure{Example} Dividing the sample of heights by sex we get two subsamples
% \begin{center}
% \begin{tabular}{lll}
% \hline
% \multirow{2}{*}{Women} &
% 173, 158, 174, 166, 162, 177, 165, 154, 166, 182, \\
% & 169, 172, 170, 168. \\
% \hline
% \multirow{2}{*}{Men} &
% 179, 181, 172, 194, 185, 187, 198, 178, 188, 171,\\
% & 175, 167, 186, 172, 176, 187. \\
% \hline
% \end{tabular}
% \end{center}
% \end{frame}
% 
% 
% %---------------------------------------------------------------------slide----
% \begin{frame}
% \frametitle{Comparing distributions for the levels of a factor }
% 
% \begin{center}
% \scalebox{0.5\textwidth}{\input{img/descriptive/factor_histogram}}
% \quad
% \scalebox{0.5\textwidth}{\input{img/descriptive/factor_box_plot}}
% \end{center}
% \end{frame}
